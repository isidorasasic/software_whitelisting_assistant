from software_whitelisting_assistant.scripts.classes import Tool
from software_whitelisting_assistant.scripts.llm_client import call_llm
from software_whitelisting_assistant.scripts.artifacts_store import load_prompt

def generate_tool(
    model: str, 
    temperature: float, 
    max_tokens: int, 
    prompt_name: str
) -> Tool:
    """
    Generate a Tool definition using an LLM.

    Args:
        model (str): Name of the LLM model to use.
        temperature (float): Sampling temperature for generation.
        max_tokens (int): Maximum number of tokens allowed for generation.
        prompt_name (str): Name of the prompt template used for tool generation.

    Returns:
        Tool: A validated Tool object generated by the LLM.

    Raises:
        ValidationError: If the LLM output cannot be validated as a Tool.
    """

    prompt = load_prompt(prompt_name)

    tool = call_llm(
        prompt=prompt,
        model=model,
        temperature=temperature,
        max_tokens=max_tokens,
        text_format=Tool
    )

    return Tool.model_validate(tool)

    